{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://rupeshs-mbp.fios-router.home:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import calendar\n",
    "import datetime\n",
    "\n",
    "# Clean Taxi Data\n",
    "def parserTaxi(id, data):\n",
    "    if id == 0:\n",
    "        data.next()\n",
    "    for i in csv.reader(data):\n",
    "        tpep_pickup_datetime, tpep_dropoff_datetime, pickup_longitude, \\\n",
    "        pickup_latitude, dropoff_longitude, dropoff_latitude, Date, Weekday = i[1], i[2], i[5], i[6], i[9], i[10], \\\n",
    "        datetime.datetime.strptime(i[1], \"%Y-%m-%d %H:%M:%S\").date(), \\\n",
    "        calendar.day_name[datetime.datetime.strptime(i[1], \"%Y-%m-%d %H:%M:%S\").weekday()]\n",
    "        # rows required for the taxi data\n",
    "        yield tpep_pickup_datetime, tpep_dropoff_datetime, pickup_longitude, \\\n",
    "        pickup_latitude, dropoff_longitude, dropoff_latitude, Date, Weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 4):\n",
    "    taxi = sc.textFile('Data/top20-{0}.csv'.format(i), use_unicode=False).cache()\n",
    "    taxiRDD = taxi.mapPartitionsWithIndex(parserTaxi)\n",
    "    df = sqlContext.createDataFrame(taxiRDD, ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'Date', 'Weekday'])\n",
    "    agg = df.select('Date').groupBy('Date').count()\n",
    "    agg.coalesce(1).write.csv('Data/top20-{0}_AGG'.format(i), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = sc.textFile('Data/WeatherData2016Clean.csv', use_unicode=False).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ''), (1, 'Date'), (2, 'DateVal'), (3, 'Temp'), (4, 'Conditions')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(weather.first().split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'VendorID'),\n",
       " (1, 'tpep_pickup_datetime'),\n",
       " (2, 'tpep_dropoff_datetime'),\n",
       " (3, 'passenger_count'),\n",
       " (4, 'trip_distance'),\n",
       " (5, 'pickup_longitude'),\n",
       " (6, 'pickup_latitude'),\n",
       " (7, 'RatecodeID'),\n",
       " (8, 'store_and_fwd_flag'),\n",
       " (9, 'dropoff_longitude'),\n",
       " (10, 'dropoff_latitude'),\n",
       " (11, 'payment_type'),\n",
       " (12, 'fare_amount'),\n",
       " (13, 'extra'),\n",
       " (14, 'mta_tax'),\n",
       " (15, 'tip_amount'),\n",
       " (16, 'tolls_amount'),\n",
       " (17, 'improvement_surcharge'),\n",
       " (18, 'total_amount')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(taxi.first().split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def weather_hours_mapper(id, data):\n",
    "    if id == 0:\n",
    "        data.next()\n",
    "    for row in csv.reader(data):\n",
    "        yield row\n",
    "        \n",
    "weatherRDD = weather.mapPartitionsWithIndex(weather_hours_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '01/01/2016', '1', '38', 'Normal'],\n",
       " ['1', '01/02/2016', '2', '36', 'Normal'],\n",
       " ['2', '01/03/2016', '3', '40', 'Normal']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',Date,DateVal,Temp,Conditions',\n",
       " '0,01/01/2016,1,38,Normal',\n",
       " '1,01/02/2016,2,36,Normal']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(taxi.first().split(',')))\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(id, data):\n",
    "    if id == 0:\n",
    "        data.next()\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        yield (row[7], 1)\n",
    "        \n",
    "# Clean Taxi Data\n",
    "def parserTaxi(id, data):\n",
    "    if id == 0:\n",
    "        data.next()\n",
    "    for i in csv.reader(data):\n",
    "        tpep_pickup_datetime, tpep_dropoff_datetime, pickup_longitude, \\\n",
    "        pickup_latitude, dropoff_longitude, dropoff_latitude, Date, Weekday = i[1], i[2], i[5], i[6], i[9], i[10], \\\n",
    "        datetime.datetime.strptime(i[1], \"%Y-%m-%d %H:%M:%S\").date(), \\\n",
    "        calendar.day_name[datetime.datetime.strptime(i[1], \"%Y-%m-%d %H:%M:%S\").weekday()]\n",
    "        # rows required for the taxi data\n",
    "        yield tpep_pickup_datetime, tpep_dropoff_datetime, pickup_longitude, \\\n",
    "        pickup_latitude, dropoff_longitude, dropoff_latitude, Date, Weekday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxiRDD = taxi.mapPartitionsWithIndex(parserTaxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2016-06-09 21:06:36',\n",
       "  '2016-06-09 21:13:08',\n",
       "  '-73.983360290527344',\n",
       "  '40.760936737060547',\n",
       "  '-73.977462768554688',\n",
       "  '40.753978729248047',\n",
       "  datetime.date(2016, 6, 9),\n",
       "  'Thursday'),\n",
       " ('2016-06-09 21:06:36',\n",
       "  '2016-06-09 21:35:11',\n",
       "  '-73.981719970703125',\n",
       "  '40.736667633056641',\n",
       "  '-73.981636047363281',\n",
       "  '40.670242309570313',\n",
       "  datetime.date(2016, 6, 9),\n",
       "  'Thursday'),\n",
       " ('2016-06-09 21:06:36',\n",
       "  '2016-06-09 21:13:10',\n",
       "  '-73.994316101074219',\n",
       "  '40.751071929931641',\n",
       "  '-74.004234313964844',\n",
       "  '40.742168426513672',\n",
       "  datetime.date(2016, 6, 9),\n",
       "  'Thursday'),\n",
       " ('2016-06-09 21:06:36',\n",
       "  '2016-06-09 21:36:10',\n",
       "  '-73.98236083984375',\n",
       "  '40.773891448974609',\n",
       "  '-73.929466247558594',\n",
       "  '40.851539611816406',\n",
       "  datetime.date(2016, 6, 9),\n",
       "  'Thursday'),\n",
       " ('2016-06-09 21:06:36',\n",
       "  '2016-06-09 21:23:23',\n",
       "  '-73.987106323242187',\n",
       "  '40.733173370361328',\n",
       "  '-73.985908508300781',\n",
       "  '40.766445159912109',\n",
       "  datetime.date(2016, 6, 9),\n",
       "  'Thursday')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxiRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.createDataFrame(taxiRDD, ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude', 'Date', 'Weekday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thursday'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import calendar\n",
    "calendar.day_name[datetime.datetime.strptime(\"2016-06-09 21:06:36\", \"%Y-%m-%d %H:%M:%S\").weekday()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = df.select('Date').groupBy('Date').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Date=datetime.date(2016, 6, 9), count=19)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg.coalesce(1).write.csv('Data/yellow_tripdata_2016-12_AGG', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all the 0 lat data\n",
    "taxiDF = taxiDF.filter(taxiDF._3 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherDF = weatherRDD.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(_1=u'0', _2=u'01/01/2016', _3=u'1', _4=u'38', _5=u'Normal')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: string, _2: string, _3: string, _4: string, _5: string, _6: string, _7: date, _8: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxiDF.limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(data):\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        yield row[7]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedTaxi = sc.textFile('Data/merged_Data_Taxi.csv', use_unicode=False).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = mergedTaxi.map(lambda x: (x, 1)).reduceByKey(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
